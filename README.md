chinese-ner-pytorch

---

本项目是一个简单的采用`pytorch`框架的中文命名实体识别demo，主要是为了熟悉NER中两种常见的经典模型：`lstm`和`lstm+crf`,以及`BERT`预训练模型，代码中在必要的地方都有详细的注释，希望对有相关需求的人有帮助

### 数据集

数据集采用的是经典的`MSRA`数据集，[下载地址](https://www.cluebenchmarks.com/dataSet_search_modify.html?keywords=%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB)，总共包括训练集、验证集和测试集，它们的数据规模如下：

- 训练集: 42000
- 验证集: 3000
- 测试集: 3442

### 模型

主要测试了三种模型：

- `lstm`：（经典的NER模型）
- `lstm + crf`：（大多数实验表明，加了CRF之后效果会更好）
- `BERT`：（预训练模型出来之后的SOTA模型）

### 结果

以下结果只是初步跑了一遍模型，没有对模型进行各种花式的调参，得到的F1值并不高，因为本项目的主要目的也只是为了熟悉下NER任务中两种常用的模型，所以就没有进一步采用其它tricks来提分；

| 模型     | Precision | Recall | F1    |
| -------- | --------- | ------ | ----- |
| Lstm     | 73.83     | 79.43  | 76.45 |
| lstm+CRF | 74.32     | 79.45  | 76.68 |
| BERT     | 78.01     | 82.11  | 79.94 |

> BERT这一类预训练模型的拟合能力真的很强，只训练了5个epcoh就基本收敛了，所以没有继续训练下去（如果调整学习率继续的话应该还会涨点分）
